# MNIST Classifier

Проект для классификации рукописных цифр (0-9) с использованием нейронной сети на основе датасета MNIST.

## Описание проекта

Этот проект реализует глубокую нейронную сеть для распознавания рукописных цифр. Модель обучается на 60,000 изображений цифр размером 28x28 пикселей и тестируется на 10,000 изображений. Проект включает:

- Загрузку и предобработку данных MNIST
- Создание и обучение нейронной сети с архитектурой:
  - Входной слой (28x28)
  - Flatten слой
  - Dense слой (128 нейронов, ReLU)
  - Dropout (0.2)
  - Dense слой (64 нейрона, ReLU)  
  - Dropout (0.1)
  - Выходной слой (10 нейронов, Softmax)
- Визуализацию результатов обучения
- Анализ ошибок и матрицу путаницы

## Требования

- Python 3.7+
- TensorFlow/Keras
- NumPy
- Matplotlib
- scikit-learn

## Установка и настройка

### 1. Клонирование проекта

```bash
cd /path/to/your/projects
git clone <repository-url>
cd mnist-classifier
```

### 2. Создание виртуальной среды

```bash
# Создание виртуальной среды
python -m venv venv

# Активация виртуальной среды
# На Linux/macOS:
source venv/bin/activate
# На Windows:
# venv\Scripts\activate
```

### 3. Установка зависимостей

Создайте файл `requirements.txt` со следующим содержимым или используйте существующий:

```
tensorflow>=2.10.0
numpy>=1.21.0
matplotlib>=3.5.0
scikit-learn>=1.0.0
```

Установите зависимости:

```bash
pip install -r requirements.txt
```

### 4. Запуск проекта

```bash
python src/main.py
```

## Структура проекта

```
mnist-classifier/
├── src/
│   └── main.py          # Основной файл с логикой обучения
├── logs/                # Папка с лог-файлами (создается автоматически)
├── results/             # Папка с графиками результатов (создается автоматически)
├── requirements.txt     # Файл зависимостей
├── README.md           # Этот файл
└── .gitignore          # Файлы для игнорирования Git
```

## Результаты работы

### Логирование

Все этапы обучения записываются в лог-файл в папке `logs/` с именем формата:
```
training_log_YYYYMMDD_HHMMSS.log
```

Лог содержит информацию о:
- Загрузке данных
- Размерах обучающего и тестового наборов
- Процессе обучения
- Итоговых метриках точности и потерь

### Визуализация

После завершения обучения генерируются два файла с графиками в папке `results/`:

1. **`training_results_YYYYMMDD_HHMMSS.png`** - сводный график с 4 подграфиками:
   - Функция потерь (loss) на обучающей и валидационной выборках
   - Точность (accuracy) на обучающей и валидационной выборках  
   - Матрица путаницы (confusion matrix)
   - Пример ошибочно классифицированного изображения

2. **`loss_and_accuracy_YYYYMMDD_HHMMSS.png`** - отдельные графики потерь и точности

### Ожидаемые результаты

- Точность на тестовой выборке: ~97-98%
- Время обучения: 5-10 минут на CPU
- Размер модели: небольшой (полносвязная сеть)

## Особенности реализации

- **CPU-only обучение**: проект настроен на использование только CPU для совместимости
- **Подавление предупреждений**: отключены verbose сообщения TensorFlow
- **Автоматическое создание папок**: директории для логов и результатов создаются автоматически
- **Timestamp в именах файлов**: все выходные файлы содержат дату и время создания

## Параметры модели

- **Эпохи обучения**: 15
- **Batch size**: 128  
- **Валидационная выборка**: 10% от обучающих данных
- **Оптимизатор**: Adam
- **Функция потерь**: categorical_crossentropy

## Устранение неполадок

### Ошибки при установке TensorFlow

```bash
# Если возникают проблемы с TensorFlow, попробуйте:
pip install tensorflow-cpu
```

### Проблемы с matplotlib на Linux

```bash
# Если matplotlib не отображает графики:
sudo apt-get install python3-tk
```

### Ошибки памяти

Если возникают ошибки нехватки памяти, уменьшите batch_size в файле `src/main.py`:

```python
# Измените строку:
batch_size=128
# На:
batch_size=64  # или меньше
```

## Дальнейшее развитие

Возможные улучшения проекта:
- Добавление сверточных слоев (CNN) для повышения точности
- Реализация сохранения/загрузки обученной модели
- Веб-интерфейс для загрузки и классификации собственных изображений
- Аугментация данных для улучшения обобщающей способности
- Сравнение различных архитектур моделей
